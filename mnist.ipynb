{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d3ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe46cf44",
   "metadata": {},
   "source": [
    "`torchvision`: pytorch extension that provides datasets, model architectures, and image transformation utils\n",
    "`torchvision.transform`: contains image transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b378c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7556ec6",
   "metadata": {},
   "source": [
    "`transforms.ToTensor()`: converts an image (which is originally represented as a PIL Image or a numpy array) into a PyTorch tensor. Specifically, it converts the image's pixel values to a tensor and scales them to the range [0, 1]. So, each pixel's value is divided by 255 to bring it into the [0, 1] range.\n",
    "\n",
    "`transforms.Normalize((0.5), (0.5))`: normalize the picture values\n",
    "- Subtract 0.5: This step shifts the values from [0, 1] to [-0.5, 0.5]. It centers the data around zero.\n",
    "- Divide by 0.5: This step scales the values from [-0.5, 0.5] to [-1, 1]. The purpose of this step is to ensure that the input data to the neural network has a mean of 0 and a standard deviation of 1, which can help with training stability. \n",
    "\n",
    "___This will result in a tensor with values in the range of [-1, 1], which is a common preprocessing step for training deep neural networks. (to help network learn effectively and make the training process converge faster)___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc602d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330d9b7",
   "metadata": {},
   "source": [
    "`trainloader`, responsible batching, shuffling, and providing data to the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0bbeaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN architecture\n",
    "# let's now build a simple model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(24*24*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7f80dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "net = Net()\n",
    "# define loss func\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# define optimizer \n",
    "optimizer = optim.SGD(net.parameters(), lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f27f3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 1.142\n",
      "[1,   400] loss: 0.413\n",
      "[1,   600] loss: 0.352\n",
      "[1,   800] loss: 0.297\n",
      "[2,   200] loss: 0.246\n",
      "[2,   400] loss: 0.210\n",
      "[2,   600] loss: 0.213\n",
      "[2,   800] loss: 0.186\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "# loop over the dataset 5 times\n",
    "for epoch in range(5):\n",
    "    running_loss = .0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0dd201",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c91247ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=36864, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bd06dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 94.67%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # disable gradient tracking during evaluation for efficiency\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1a5c7",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6ad0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN architecture\n",
    "# let's now build a simple model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(30976, 360)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(360, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f3193ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model = Model()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=.7) # decay LR by a factor of 0.7 every epoch\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8b807d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.324\n",
      "[1,   400] loss: 0.099\n",
      "[1,   600] loss: 0.075\n",
      "[1,   800] loss: 0.061\n",
      "[2,   200] loss: 0.044\n",
      "[2,   400] loss: 0.040\n",
      "[2,   600] loss: 0.038\n",
      "[2,   800] loss: 0.042\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2982d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=30976, out_features=360, bias=True)\n",
       "  (fc2): Linear(in_features=360, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "908ec626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 98.82%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # disable gradient tracking during evaluation for efficiency\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f661e5b5",
   "metadata": {},
   "source": [
    "`input_batch = input_tensor.unsqueeze(0)`: add batch dimension to the input tensor; this is necessary because deep learning models typically expect input data to be organized in batches, even if we are processing a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c30f4be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "The predicted class is: 6\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = './digit6.png'\n",
    "\n",
    "def load_and_preprocess_img(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    # convert it to grayscale\n",
    "    image = image.convert('L')\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    # preprocess the image\n",
    "    input_tensor = preprocess(image)\n",
    "    print(input_tensor.shape)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # add a batch dimension\n",
    "    return input_batch\n",
    "\n",
    "def classify_number(image_path):\n",
    "    input_batch = load_and_preprocess_img(image_path)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "        \n",
    "    # Get the predicted class\n",
    "    _, predicted_idx = torch.max(output, 1)\n",
    "    predicted_class = predicted_idx.item()\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "\n",
    "# Classify the number in the image\n",
    "predicted_class = classify_number(image_path)\n",
    "print(f'The predicted class is: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca095d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6cc346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a5b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd95f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab25ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96e31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592eab31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f984f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350631eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9320842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa97948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a26be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f804335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        return False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
